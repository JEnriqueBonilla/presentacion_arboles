---
title: "Árboles de Clasificación y regresión"
subtitle: "Introducción al Aprendizaje Estadístico"
author: "Kael Huerta, Enrique Bonilla"
date: "`r Sys.Date()`"
output:
  tufte::tufte_html: default
  tufte::tufte_handout:
    citation_package: natbib
    latex_engine: xelatex
  tufte::tufte_book:
    citation_package: natbib
    latex_engine: xelatex
header-includes: 
- \usepackage[spanish]{babel}
- \usepackage[utf8]{inputenc}
- \usepackage{amsmath,amsfonts,amsthm}
- \usepackage{graphicx}
bibliography: bibliografia.bib
link-citations: yes
nocite: | 
  @notas
---

---

```{r setup, include = F}
library(tufte)
## invalidate cache when the tufte version changes
knitr::opts_chunk$set(tidy = FALSE, cache.extra = packageVersion('tufte'))
options(htmltools.dir.version = FALSE)
```


### Nota: los paquetes que se utilizaran en estas notas son los siguientes:
```{r,echo = T, warning = F, message = F,error = F}
require(ggplot2)
require(ggdendro)
require(plyr)
require(dplyr)
require(tidyr)
require(kknn)
require(rpart)
require(tree)
require(mlbench)
require(randomForest)
require(gbm)
require(data.table)
```

```{r, echo = F}
## Cambiando el tema de las gráficas
theme_set(theme_bw())
```

# Introducción 


## Aprendizaje Estadístico

En el mundo del análisis de datos existen 2 formas de concebir el 
modelado estadístico:
    
- **Data modeling culture**: su objetivo es el diagnóstico.
Fuerte en teoría y utiliza pocos datos.

- **Algorithmic modeling culture**: su finalidad es predecir
futuras observaciones. Aunque no se ha desarrollado
mucha teoría matemática, se desempeña muy bien ante 
grandes cantidades de datos.

Cada uno de estos enfoques es útil en distintas situaciones. 
En particular, el Aprendizaje Estadístico utiliza el segundo enfoque. 
    
Algunos términos relacionados que son frecuentemente mencionados en
la literatura son los siguientes:

- **Aprendizaje de Máquina**: análisis de algoritmos.
- **Minería de Datos**: bases de datos grandes.
- **Aprendizaje estadístico**: teoría estadística detrás de
las últimas dos.

El aprendizaje estadístico se divide en dos principales ramas:
   
- **Aprendizaje Supervisado**: predecir la variable dada $Y$ 
    (conocemos la respuesta). Si la variable de respuesta es
    cuantitativa se conoce como problema de *regresión*. 
    Si es cualitativa, se denomina problema de *clasificación*.
- **Aprendizaje No Supervisado**: no hay variable respuesta.
Se trata de encontrar estructuras intrínsecas en los datos.

```{r fig-two-separate, fig.cap=sprintf("Aprendizaje supervisado. Problema de %s.", c("regresión", "clasificación")), cache = F}

## Método: regresión lineal
## Datos: old faithful géiser en Yellowstone National Park, Wyoming, USA
## Librerias: base
 
faithful %>%
  ggplot(aes(x = eruptions, y = waiting)) + 
    geom_point() +
    geom_smooth(method='lm') +
    xlab("Duración de erupción (min.)") + 
    ylab("Tiempo de espera para siguiente erupción (min.)")

## Método: regresión lineal
## Datos: flores de Fisher
## Librerias: base

datos <- iris %>% 
  filter(Species %in% c("setosa", "versicolor") ) %>% 
  mutate(specie = as.numeric(ifelse(Species== "setosa", 0, 1)))
  
modelo <- datos %>% 
  lm(formula = "specie ~ Sepal.Length + Sepal.Width")

## Si y > .5 entonces se clasifica 1

datos %>%
  ggplot(aes(x = Sepal.Length, y = Sepal.Width, colour = Species)) +
    geom_point() + 
    geom_abline(intercept = -1.28, slope = .79)  + 
    annotate("text", x = 6, y = 4, label = ".50 = -.28 + .47x1 - .59x2") +
    xlab("Longitud del sépalo") +
    ylab("Anchura del sépalo")
```


```{r fig-main, fig.cap = "Aprendizaje no supervisado. Problema de agrupamiento.", cache = F}
 
## Método: k-medias
## Datos: old faithful géiser en Yellowstone National Park, Wyoming, USA
## Librerias: base

modelo <- kmeans(faithful, 2)

datos <- data.frame(faithful, grupo = as.character(modelo$cluster))

datos %>% 
  ggplot(aes(x = eruptions, y = waiting, color = grupo)) + 
  geom_point() +
  xlab("Duración de erupción") + 
  ylab("Tiempo de espera para siguiente erupción")
```

Los *métodos basados en árboles* (CART, Bosques Aleatorios, etc.)
son algoritmos de aprendizaje supervisado. Estos pueden tener como
respuesta una variable numérica ($Y$) o una variable 
categórica ($G$).

## Supuestos y notación

Se define a $X = (X_1, \ldots, X_p)$ como la variable de entrada 
y a $Y$ como la variable de respuesta cuantitativa, $G$ en caso de ser
cualitativa. Se asume que $X$ y $Y$ están relacionadas a través de un modelo
probabilístico $P(X,Y)$ donde $P(X,Y)$ es su distribución de
probabilidad conjunta. Por lo general, $P(X,Y)$ es un objeto
complicado que no conocemos y es difícil de estimar.

En el caso de regresión, suponemos que se puede escribir $Y = f(X) + \epsilon$
donde $E[\epsilon] = 0$ y es independiente de X.^[La idea es que 
$f(X)$ captura toda la información sistemática de $X$ acerca de 
$Y$, así que $\epsilon$ es independiente de $X$.] Para este 
modelo, $f(x) = E[Y \mid X = x]$.^[En algunos problemas,
se puede suponer que $Y = f(X)$ o que los errores no son independientes
e idénticamente distribuidos.] Nuestro objetivo es estimar $f(X)$
por medio de una aproximación $\hat{f}$ usando los datos observados.
^[Típicamente, la $f$ estimada depende de un parámetro
o conjunto de parámetros de **complejidad** $\alpha$, i.e, $\hat{f}_{\alpha}$.]

Cuando se trata del problema de clasificación, nuestro objetivo es 
estimar $P(G \mid X)$ y esto se modela directamente. 

Para construir la regla de predicción ($\hat{f}$ o $\hat{P}$ 
dependiendo el caso) usamos datos observados. 
Al conjunto de datos observados $\Gamma  = \{(x_1, y_1), \ldots, (x_n, y_n)\}$ 
con los que se evalúa el modelo se le conoce como
*conjunto de entrenamiento*. 

## Teoría de decisión

Al igual que en la estadística bayesiana, el aprendizaje estadístico
se apoya de la teoría de decisión para tomar decisiones basado
en los principios de la elección coherente. Denotaremos 
a la *función de pérdida* como $L(Y,\hat{f}(X))$. En teoría, nuestro objetivo 
será encontrar $\hat{f}(X)$ dentro de una familia de funciones $F$^[Este 
problema se puede traducir en encontrar $\alpha$.] que minimice  
la *pérdida esperada* sobre observaciones futuras^[El planteamiento 
común en teoría de decisión es maximizar el valor esperado de una 
función de utilidad $U(X)$. Se puede ver que estos planteamientos 
son equivales si $U(X)= -\hat{f}(X)$.], i.e,
$$\begin{equation*}
\begin{aligned}
& \underset{f}{\text{min}}
& & E[L(Y_0,\hat{f}(X_0)] \\
& \text{s.a.} & & f\in F \\
& & & X_0,Y_0 \in P(X,Y)
\end{aligned}
\end{equation*}$$ 
En la práctica, esto se traduce a minimizar el error de predicción
de nuestro modelo condicionado a los datos de entrenamiento.


Las funciones de pérdida más comunes en la literatura son las siguientes:

- **Problema de regresión**:  $$L(Y,\hat{f}(X)) =
  \begin{cases}
    (Y - \hat{f}(X))^2       & \quad \text{pérdida cuadrática}\\
    \mid X-\hat{f}(X) \mid   & \quad  \text{pérdida absoluta}\\
  \end{cases}
$$

- **Problema de clasificación**:  
$$L(G,\hat{G}(X)) =  G \neq \hat{G} \quad \text{pérdida 0-1}$$

$$L(G, \hat{P}(G \mid X)) = -2\sum\limits_{k=1}^K I(G = k)log(\hat{P}(G = k \mid X)) \quad \text{log verosimilitud o devianza}$$

Como primera opción, uno podría pensar que una estimación
del error de predicción se puede obtener por medio del *error de entrenamiento* 
$$\bar{err} = \sum\limits_{i=1}^n L(y_i, \hat{f}(x_i))$$
con $(x_i,y_i) \in \Gamma$. Sin embargo, el error de entrenamiento
subestima, generalmente, esta cantidad. Esto es porque el error
de entrenamiento decrece constantemente al aumentar la complejidad
del modelo, típicamente llegando a cero, pues si el modelo 
es muy complejo captura ruido de $\epsilon$.

La manera correcta de estimar el error que vamos a tener 
al predecir con $\hat{f}(X)$ al ser entrenado con una muestra
$\gamma$ es estimando el *error de prueba* también conocido como
*error de predición* o *generalization error*
$$E_{rr\gamma} = E[L(Y,\hat{f}(X)) \mid \gamma]$$
donde $\gamma$ es una muestra de $P(X,Y)$.^[observemos 
que $(X,Y)$ son elementos de $P(X,Y)$ no de $\Gamma$ 
necesariamente.] 

Como se mencionó anteriormente, estimar $E_{rr\gamma}$ 
es nuestro principal objetivo pues nos revela no sólo como se 
comporta la predicción de nuestro modelo $\hat{f}(X)$, si no
que, además, sabemos como se va a comportar al ser entrenado
con el conjunto de entrenamiento $\Gamma$ que poseemos. Sin embargo, 
parece que no es posible estimar este error condicional de forma 
efectiva **_sólo con el conjunto de entrenamiento_**. Se
necesitarían datos independientes a esta muestra para hacerlo.


Lo que se puede hacer es estimar el 
*error de predicción esperado* o *error de prueba esperado*^[
$E_{rr}=E_\gamma[E_{X,Y}[L(Y,\hat{F}(X)) \mid \gamma]]$
]
$$E[L(Y,\hat{f}(X))] = E_{rr} = E[E_{rr\gamma}]$$
y usarlo para comparar y seleccionar modelos.
Este valor es más amable al análisis estadístico además
de que puede ser estimado con sólo el uso de la muestra
de entrenamiento.

<!-- El error de predicción esperado puede ser
estimado con la muestra de entrenamiento con el uso
de validación cruzada. La muestra de prueba se usa para estimar
el error de predicción (el que está condicionado a gamma)-->

El error de predicción esperado puede ser aproximado analíticamente
por métodos *in-sample* (AIC, DIC, MDL o SRR)^[En 
realidad, algunos de estos métodos estiman $E_y[E_{inn}]$. Para más 
información ver la sección 7.4 de @friedman2001elements .] 
o por métodos de reuso de muestras (validación cruzada, *bootstrap*).


Si tenemos muchos datos, lo mejor que podemos hacer es dividir
la muestra observada en 3 conjuntos ajenos:

- **Conjunto de entrenamiento**: se usa para entrenar el modelo 
(puede sobre-ajustar). Se recomienda, empíricamente $50\%$ 
de la muestra, dependiendo de su tamaño. 

- **Conjunto de prueba**: se usa para seleccionar modelos 
(aún si estima $E_{rr\gamma}$, se puede sobre-ajustar). 
Se recomienda, empíricamente, $25\%$ de
la muestra.

- **Conjunto de validación**: se utiliza para aproximar $E_{rr\gamma}$
de nuestro modelo final. Se recomienda, empíricamente, $25\%$ de
la muestra y sólo debe ser utilizado al final para calcular el error. 
**No** debe formar parte del proceso de selección de modelos (podría 
sobre-ajustar y estaría dando una sub-estimación del error de predicción real).


Si tenemos un menor tamaño de muestra, ésta se separa sólo en
conjuntos ajenos de entrenamiento ($80\%$) y validación ($20\%$). 
Con el conjunto de entrenamiento estimamos $E_{rr}$ (por medio de métodos de
reuso de muestra o *in-sample*) y comparamos / seleccionamos modelos.
Con el conjunto de validación estimamos $E_{rr\gamma}$ del modelo final. 


## Descomposición en varianza-sesgo

Si asumimos que estamos en el caso de regresión 
($Y = F(X) + \epsilon$, $E[\epsilon]=0$, $Var(\epsilon)= \sigma_\epsilon^2$)
y usamos la pérdida cuadrática se puede demostrar que ^[Por simplicidad,
supondremos que sólo nos interesa hacer predicción para $X = x_0$]
$$E_{rr}(x_0) = \sigma_\epsilon^2 + sesgo_\gamma^2(x_0) + Var_\gamma(x_0)$$

donde

- $\sigma_\epsilon^2 = Var(Y \mid X=x_0)$ es el error irreducible. 
No depende del ajuste, es aleatoriedad del fenómeno.

- $sesgo_\gamma^2(x_0) = (E[Y \mid X = x_0] -E_\gamma[\hat{f}_\gamma(x_0)])^2$ 
es el sesgo del método. Mide en promedio cuanto se desvía 
$\hat{f}_\gamma(x_o)$ del óptimo $E[y \mid X = x_0]$. Entre menos complejo sea
el método aumenta el sesgo y, por lo tanto, aumenta el error.

- $Var_\gamma(x_0) = E_\gamma[(\hat{f}_\gamma(x_0)-E_\gamma[\hat{f}_\gamma(x_0)])^2]$
es la varianza del método. mide qué tanto varían las predicciones
entre muestras de entrenamiento. Un método muy complejo es
un método inestable en el que las predicciones varían mucho
entres muestras de entrenamiento. 

Esta descomposición se encuentra, generalmente, independientemente 
de la función de pérdida y del tipo de problema. Por lo general,
$E_{rr\gamma}$ tiene un comportamiento con la misma estructura que 
$E_{rr}$ pero no igual.

Además, dicha descomposición nos muestra cómo, para minimizar el error de
predicción, es conveniente encontrar un equilibrio entre sesgo
y varianza: seleccionar un modelo suficientemente complejo para
que capture la estructura de los datos pero no tan complejo
para capturar ruido.


```{r , fig.cap = "Varianza-Sesgo: entrenamiento vs prueba.", cache = F}
 
## Método: k vecinos más cercanos
## Datos: Munich Rent Standards 
## Librerias: kknn

data(miete)

tamano <- floor(0.65 * nrow(miete))

set.seed(203040)

entrena.ind <- sample(seq_len(nrow(miete)), 
                      size = tamano)

entrena <- miete[entrena.ind, ]

prueba <- miete[-entrena.ind, ]


errores.vmc <- ldply(c(1, 5, 10, 20, 50, 100, 250, 500), 
                     function(i) {
  
    vecino.k.prueba <- kknn(nmqm ~ wfl + bjkat + zh, 
                            train = entrena, 
                            test = prueba, 
                            k = i, kernel = "rectangular")
    
    vecino.k.entrena <- kknn(nmqm ~ wfl + bjkat + zh, 
                             train = entrena, 
                             test = entrena, 
                             k = i, kernel = "rectangular")
    
    error.prueba <- mean((fitted(vecino.k.prueba) - 
                            prueba$nmqm)^2)
    error.entrena <- mean((fitted(vecino.k.entrena) - 
                             entrena$nmqm)^2)
    
    data.frame(k = i, prueba = error.prueba, 
               entrenamiento = error.entrena)
})

err.m <- errores.vmc %>% 
  gather(variable, valor, -k) %>% 
  mutate(n.k = floor(500/k) )
  
err.m %>% 
  ggplot(aes(x = factor(n.k), y = valor, 
             colour = variable,
             group = variable)) + 
  geom_line() + 
  geom_point() + 
  xlab("Grados de libertad") + 
  ylab("Error")
```

# Árboles de clasificación y regresión

Los modelos basados en árboles son herramientas poderosas
para la predicción. Estos van particionando, recursivamente, 
el espacio de covariables (*feature space*) en rectángulos 
por medio de modelos simples, como constantes. En esta 
sección, nos enfocaremos en el método *CART*^[@breiman1984classification]. 
Aunque este tipo de árboles, por si solos, son fácilmente superados 
en la predicción, consituyen la base teórica de técnicas muy poderosas 
como bosques aleatorios.

Para simplificar, aunque posteriormente veremos que en realidad
este enfoque es el más conveniente, CART hace 
particiones binarias. Primero, se parte el espacio en dos regiones
seleccionando la covariable y el corte que ajuste mejor; después,
una o ambas de estas regiones se particionan en otras dos de la misma
manera y así sucesivamente. 

Esta forma de particionar el espacio nos permite representar el modelo
gráficamente por medio de un árbol binario, lo que lo hace un modelo fácil
de interpretar: los nodos intermedios pueden entenderse como decisiones que
dependen de las covaraibles del modelo, los nodos terminales representan 
la partición final obtenida. En cada uno de los nodos terminales se elige, 
según algún criterio, un número o clase de predicción. Cómo se puede ver 
en los árboles binarios, este modelo permite capturar interacciones. 


```{r , fig.cap=sprintf("Árbol de clasificación. Representación %s.", c("espacial", "en árbol binario")), cache = F}

## Método: CART
## Datos: flores de Fisher
## Librerias: tree, rpart, ggdendro
 
## Modelos
control.completo <- rpart.control(cp=0, minsplit=10,
                                minbucket=1, xval=10, maxdepth=30)

arbol1 <- tree(Species ~ Sepal.Width + Petal.Width, data = iris)
arbol2 <- rpart(Species ~ Sepal.Width + Petal.Width, method = "class", 
               data = iris, control = control.completo)

## Particion del feature space
plot(iris$Petal.Width, iris$Sepal.Width, pch=19,col=as.numeric(iris$Species))
partition.tree(arbol1, label="Species", add = T)
legend(1.75,4.5,legend=unique(iris$Species),col=unique(as.numeric(iris$Species)),pch=19)

## Dendograma
ddata <- dendro_data(arbol2, uniform =T)

ggplot() + 
  geom_segment(data = ddata$segments, 
               aes(x = x, y = y, xend = xend, yend = yend), colour = "brown", size = 1) + 
  geom_text(data = ddata$labels, 
            aes(x = x, y = y, label = label), colour = "#006633", size = 3, vjust = -1) +
  geom_text(data = ddata$leaf_labels, 
            aes(x = x, y = y, label = label), colour = "#006633", size = 4, vjust = 1) +
  theme_dendro() 

```

Ahora queda por responder las siguientes preguntas: ¿Cómo elegir las 
particiones? ¿Cómo predecir en los nodos terminales? ¿Cómo declarar
un nodo terminal?

## Problema de regresión

Para este problema, supondremos que nuestros datos consisten 
de $p$ covariables, una variable respuesta cualitativa y $N$ 
observaciones, es decir, $(x_i,y_i)$ para $i=1, \ldots, N$ con 
$x_i = (x_{i1}, \ldots, x_{ip})$. 

Para construir nuestro árbol, recursivamente iremos dividiendo
cada nodo que se vaya generando con ayuda de las covariables del modelo 
$(X_1, \ldots, X_p)$. Se escogerá entre  particiones tales que

$$R_1(j,z) = \{X \mid X_j \leq z\} \quad \text{y} \quad R_2(j,z) = \{X \mid X_j > z\} \quad \text{si $X_j$ es continua}$$

$$R_1(j,s) = \{X \mid X_j \in s\} \quad \text{y} \quad R_2(j,s) = \{X \mid X_j \in s^c\} \quad \text{si $X_j$ es categórica}$$


Ahora bien, uno podría pensar que nuestro objetivo es dividir nuestro
espacio de covariables en las  regiones $R_1, \ldots, R_M$^[nodos terminales] 
tal que minimicen óptimamente 
$$\sum\limits_{i=1}^N (y_i - \sum\limits_{m=1}^M c_mI(x_i\in R_m))^2$$
con $c_m = promedio(y_i \mid x_i \in R_m)$. Sin embargo, este problema
no es computacionalmente factible. Lo que haremos es usar un algoritmo
codicioso para generar nuestro árbol, en otras palabras, las particiones
se escogerán de manera miope o local intentado separar las clases de 
un nodo lo mejor que se pueda.

Lo que se hace es, para cada nodo que vaya generando nuestro árbol,
encontrar la variable $j$ y el valor $z$ tal que^[Para simplificar la notación, supondremos que todas nuestras covariables son continuas.] 

$$\underset{j,z}{\text{min}}  \sum_{x_i \in R_1(j,z)}(y_i-c_1)^2 + \sum_{x_i \in R_2(j,z)}(y_i-c_2)^2 $$

Este proceso se repite hasta construir el árbol más grande que podamos 
tener.^[Mediante este algoritmo, no obtenemos la respuesta óptima pues
necesitaríamos "equivocarnos" para encontrarla.] Después nos encargaremos 
de *podarlo* para tener un mejor árbol predictor.

Se define la *impureza* de un nodo $t$ de un árbol $T$, para el problema 
de regresión, como $$i(t) = \frac{1}{N_t}\sum_{x_i \in R_t}(y_i-c_t)^2$$  y la
*impureza del árbol* como $$i(T) = \sum_{t \in T}q(t)i(t)$$ con $q(t) = N_t$.
Se puede ver que nuestro algoritmo miope se puede traducir a 
$$\underset{t -> t_1\cup t_2}{\text{min}} N_{t_1}i(t_1) + N_{t_2}i(t_2)$$
para todos los nodos que se vayan generando con la finalidad de disminuir 
la impureza del árbol lo más que se pueda. 

Una vez construido el árbol, para un valor $x_i$, $x_i \in R_m$
se predice el valor $c_m$.

## Problema de clasificación

Para el problema de clasificación, se pueden utilizar varias 
medidas de impureza. Estás usan las proporciones de casos 
en un nodo $t$ que caen en cada categoría $(p_1(t), \ldots, p_K(t))$ 
para dar una cuantificación de su impureza. 

Las más populares son las siguientes:

- **Entropía**: mide la revoltura o desorden de las clases,
es parecida a la devianza.^[La teoría estipula logaritmo base 2,
sin embargo, se puede usar cualquier base.]

$$i(t) = - \sum\limits_{k=1}^Kp_k(t)log(p_k(t))$$

- **Índice de Gini**: mide la "varianza" de las categorías,
es suma de varianzas bernoulli (multinomial).

$$i(t) = \sum\limits_{k=1}^Kp_k(t)(1-p_k(t)) = 1 -\sum\limits_{k=1}^Kp_k(t)^2$$

- **Error de clasificación**: calcula el porcentaje
de casos que mal clasificados con respecto a la categoría
más frecuente en el nodo.

$$i(t) = 1 - \underset{j}{\text{max}}(p_j(t))$$

Cuando $K=2$ estas 3 medidas se comportan similarmente.
Sin embargo, cuando $K > 2$ se recomienda usar, para
crecer el árbol, Gini o Entropía debido a que contemplan
lo que pasa a lo largo de todas las clases, no sólo la
clase dominante.^[Por ejemplo si tenemos los nodos $(500,200,200)$
y $(500,50,350)$ el error de clasificación es el mismo
pero el segundo nodo es mejor porque separa mejor las clases.]

```{r , fig.cap = "Comparación de medidas de impureza. K = 2.", cache = F}
 
gini <- function(p){
  f <- 1-p^2 -(1-p)^2
  return(f)
}

entropia <- function(p){
  f <- -p*log2(p) - (1-p)*log2(1-p)
  f <- f/2
  return(f)
  }

clasificacion <- function(p){
  f <- 1-pmax(p,(1-p))
  return(f)
}

datos <- data.frame(x = seq(0.001, .999, length =300 )) %>%  
  mutate(gini = gini(x), entropia_escalada = entropia(x), 
         clasificacion = clasificacion(x)) %>% 
  gather(variable, valor, -x)

datos %>% ggplot(aes(x = x, y = valor, group = variable, color = variable)) +
  geom_line() + 
  ylab("y")
```

Para el caso de clasificación, la impureza del árbol 
está dada por 

$$i(T) = \sum_{t \in T}q(t)i(t)$$ con $q(t) = \frac{N_t}{N}$.

y nos interesa resolver en todos los nodos^[Se usa $\frac{N_{t_1}}{N_t}$ y $\frac{N_{t_1}}{N_t}$ para
que sea un problema local.] 
$$\underset{t -> t_1\cup t_2}{\text{min}} \frac{N_{t_1}}{N_t}i(t_1) + \frac{N_{t_2}}{N_t}i(t_2)$$
 

Una vez construido el árbol, para un valor $x_i$, $x_i \in R_m$
se predice con la categoría más frecuente en el nodo.

## Costo-Complejidad

Como se mencionó en la sección anterior, como primer paso para
construir nuestro árbol final, el que utilizaremos para predecir,
construiremos el árbol más grande posible $T_{max}$. Sin embargo, 
este árbol va a tener varianza alta debido a que es un modelo muy 
complejo y está sobre-ajustando, lo que nos llevaría a un gran error de 
predicción.

Lo que se puede hacer es pensar en un criterio de paro para el 
tamaño del árbol. Una primera opción podría ser dividir un 
nodo sólo si el decrecimiento en la impureza del árbol excede
alguna cuota, pero con este criterio podríamos perder buenas 
separaciones debajo de las separaciones malas.

Una mejor estrategia es podar el árbol (*prunning*) mediante
el *costo-complejidad*. Este consiste en sumarle a la impureza
del árbol o el error de clasificación (dependiendo el caso) una
penalización por el tamaño del árbol $\mid T \mid$ multiplicado
por una constante fija $\alpha$, es decir,

$$c_\alpha(T) = i(T) + \alpha\mid T \mid$$

En un principio uno podría pensar en encontrar un árbol óptimo
$T^*(\alpha)$ que minimice $c_\alpha(T)$ para toda $\alpha \geq 0$^[
$\alpha$ más grande penaliza más fuerte el tamaño del árbol y lleva a 
soluciones con árboles más chicos.] y hacer validación cruzada 
para elegir el mejor parámetro, pero este es un problema demasiado 
grande. 

Para resolver este problema, se puede demostrar que para cada
$\alpha$ existe un único árbol que minimiza el error de 
costo-complejidad. Además, vale la pena observar que todas soluciones
$T^*(\alpha)$ son sub-árboles del árbol más grande $T_{max}$ y que, a pesar
de que existen un número infinito de $\alpha \geq 0$ sólo existe
un número finito de sub-árboles. 

@breiman1984classification demuestra que existe una sucesión anidada
de árboles  $T_{max} \leq T_1 \leq T_2 \leq \ldots \leq T_{k+1}$  y una
succión correspondiente $\alpha_0 \leq \alpha_1 \leq \ldots \leq \alpha_k$
tal que $T^*(\alpha) = T_j$ si $\alpha_{j-1} \leq \alpha < \alpha_j$, es decir,
no necesitamos explorar todas las combinaciones posibles de cortes del
árbol más grande para encontrar una solución para una determinada $\alpha$ y, 
además, no necesitamos encontrar el comportamiento de los árboles para todas 
las  $\alpha \geq 0$, sólo nos basta encontrar el árbol óptimo para un número
finito de $\alpha$ y estos árboles son sub-árboles del árbol óptimo generado
por $\alpha$ más chica. 

Una ves hecho esto encontramos cuál de estos árboles nos da el menor 
error de predicción o de validación cruzada y ese lo elegimos como 
el árbol final.

Como nota final, el costo complejidad para problemas de clasificación
está dado por 
$$c_\alpha(T) = \bar{err} + \alpha\mid T \mid$$ 
Aunque también se puede usar la impureza del árbol es más
común que se use el error de clasificación calculado con
la muestra de entrenamiento. 

## Ventajas 

- Son fáciles de interpretar.

- Capturan interacciones entre las covariables.

- No es necesario transformar variables.

- Son robustos a valores atípicos ya que pueden crear un nodo 
exclusivo para ese valor y las decisiones de clasificación 
son muy generales.

- Son robustos ante valores faltantes pues 1) pueden considerar
el valor faltante, si la covariable es categórica, con una categoría
más y ver que los individuos con valores faltantes se comportan
distinto a los que si respondieron y 2) crean cortes sucedáneos
buscando variables de entrada que más asemejen el corte encontrado.

- Se ajustan rápidamente.

- Usan cortes binarios para evitar que se acaben los datos en los nodos
muy rápido. además de que cortes múltiples pueden ser recreados por
una serie de varios cortes binarios.

- Se pueden usar combinaciones lineales para separar un nodo, 
pero se pierde interpretabilidad.

## Desventajas

- Difícilmente capturan estructuras lineales (regresión lineal).

- En la interpretación, algunas covariables pueden enmascarar a otras.
Una variable que no está en el árbol no quiere decir que no sea buena 
(cortes sucedáneos, qué tan cerca estuvieron de ganar).

- Son muy inestables ($Var_\gamma(T)$ es muy alta). Debido a que son 
modelos jerárquicos, es muy fácil que con un pequeño cambio en la muestra 
cambie radicalmente el árbol. Esto produce un desempeño predictor
relativamente malo (para este punto, también conviene ver los cortes
sucedáneos).

- Cuando tienen como covariable una variable categórica con muchas 
categorías el árbol sobre-ajusta muy rápido. Esto se debe a lo
exhaustivo de la búsqueda (como se construyen los cortes de variables
categóricas, ver @breiman1984classification o @friedman2001elements )

## Ejemplo

```{r , fig.cap = c("Árbol completo", "Error de validación cruzada (x-val)", "Error de prueba vs error de entrenamiento", "Árbol podado"), cache = F}

## Método: CART (regresión)
## Datos: Boston Housing (librería mlbench):
## Housing data for 506 census tracts of Boston from the 1970 census
## medv =	median value of owner-occupied homes in USD 1000's
## Librerias: rpart, ggdendro
 
data(BostonHousing)
set.seed(15)
train <- sample(1:nrow(BostonHousing),400)
BostonHousing$train <- F
BostonHousing$train[train] <- T
entrena.arb <- BostonHousing[BostonHousing$train,]
prueba.arb <- BostonHousing[!BostonHousing$train,]
entrena.arb$train <- NULL

## Modelo completo
modelo.arb.completo <- rpart(medv~., data = entrena.arb, method = "anova", 
                       control=rpart.control(cp=0 , xval=10, minbucket=1))

## Dendograma completo
ddata <- dendro_data(modelo.arb.completo , uniform =T)

ggplot() + 
  geom_segment(data = ddata$segments, 
               aes(x = x, y = y, xend = xend, yend = yend), colour = "brown", size = 1) + 
  geom_text(data = ddata$labels, 
            aes(x = x, y = y, label = label), colour = "#006633", size = 1, vjust = -1) +
  geom_text(data = ddata$leaf_labels, 
            aes(x = x, y = y, label = label), colour = "#006633", size = 1, vjust = 1) +
  theme_dendro() + scale_y_reverse(expand = c(0.2, 0)) + coord_polar(theta="x")

## Validación cruzada: cp = 15
plotcp(modelo.arb.completo)

error.completo <- modelo.arb.completo$cptable %>%
  data.frame() %>% 
  dplyr::select(nsplit, CP, xerror) 

error.completo %>% head(40)

alpha <- error.completo$CP

## Prueba vs entrenamiento
errores.vmc <- ldply(alpha, 
                     function(i) {
                       
                      modelo <- rpart(medv~., data = entrena.arb, method = "anova", 
                                                             control=rpart.control(cp=i , xval=10, minbucket=1))
                      
                      error.entrena <- mean((predict(modelo) - entrena.arb$medv)^2)
                       
                      error.prueba <- mean((predict(modelo, prueba.arb)- prueba.arb$medv)^2)
                       
                       data.frame(CP = as.numeric(i), prueba = error.prueba, 
                                  entrenamiento = error.entrena)
                     })

errores.vmc %>% 
  left_join(error.completo %>% 
              dplyr::select(-xerror)) %>% 
  gather(variable, valor, -CP, -nsplit) %>% 
  ggplot(aes(x = nsplit, y = valor, 
             colour = variable,
             group = variable)) + 
  geom_line() +
  geom_vline(xintercept = 19) +
  xlab("Altura del árbol") + 
  ylab("Error")

## Modelo podado

modelo.arb.final <- rpart(medv~., data = entrena.arb, method = "anova", 
                             control=rpart.control(cp=.0035 , xval=10, minbucket=1))

## Dendograma podado

ddata <- dendro_data(modelo.arb.final , uniform =T)

ggplot() + 
  geom_segment(data = ddata$segments, 
               aes(x = x, y = y, xend = xend, yend = yend), colour = "brown", size = 1) + 
  geom_text(data = ddata$labels, 
            aes(x = x, y = y, label = label), colour = "#006633", size = 3, vjust = -1) +
  geom_text(data = ddata$leaf_labels, 
            aes(x = x, y = y, label = label), colour = "#006633", size = 3, vjust = 1) +
  theme_dendro() 

## error de prueba

mean((predict(modelo.arb.final, prueba.arb)- prueba.arb$medv)^2)
```


<!---------------------------------------------------------------------------->
<!------------------------ Empiezan siguientes temas ------------------------->
<!---------------------------------------------------------------------------->

# Bagging, Bosques Aleatorios y Boosting

Como vimos, los árboles de clasificación sufren de varianza inherente al
modelo alta aunque sesgo bajo.^[Recordemos: $E_{rr}(x_0) = \sigma_\epsilon^2
+ sesgo_\gamma^2(x_0) + Var_\gamma(x_0)$]. La idea de los métodos que
veremos a continuación es aumentar el sesgo *suavizando* la predicción al
promediar la predicción de distintos árboles.

## Bagging

Intuitivamente, *bagging* es considerar la *sabiduría de las masas*.

Consideremos $L^1, L^2, ..., L^B$ muestras **independientes** e idénticamente
distribuidas del mismo fenómeno $F(x)$. Si con cada una obtenemos un árbol
$T_{L^i}$, definimos
$$T'(x) = 1/B \sum_{i=1}^B T_{L^i}(x)$$
de manera que la predicción de $T'(x)$ es el promedio de los árboles
$T_{L^i}(x)$

# Referencias

Pattern Recognition and Machine Learning

